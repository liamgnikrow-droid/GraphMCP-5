#!/usr/bin/env python3
"""
–ú–∞—Å—Å–æ–≤–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –≥—Ä–∞—Ñ–∞:
1. –ú–∏–≥—Ä–∞—Ü–∏—è CONTAINS -> DECOMPOSES
2. –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∫–∞–Ω–æ–Ω–∏—á–Ω—ã—Ö —Å–≤—è–∑–µ–π (ALLOWS_CONNECTION, CAN_PERFORM)  
3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ Functions
4. –û—á–∏—Å—Ç–∫–∞ —Å–≤–æ–π—Å—Ç–≤–∞ depends_on –∏–∑ —É–∑–ª–æ–≤ (–æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Å–≤—è–∑–∏)
"""
import sys
sys.path.append("/opt/tools")
from db_config import get_driver, close_driver

def migrate_contains_to_decomposes():
    """–ú–∏–≥—Ä–∞—Ü–∏—è CONTAINS -> DECOMPOSES"""
    print("=" * 60)
    print("–ó–ê–î–ê–ß–ê 1: –ú–∏–≥—Ä–∞—Ü–∏—è CONTAINS -> DECOMPOSES")
    print("=" * 60)
    
    driver = get_driver()
    
    # Check existing CONTAINS relationships
    check_q = """
    MATCH (parent)-[r:CONTAINS]->(child)
    RETURN count(r) as count, labels(parent)[0] as parent_type, labels(child)[0] as child_type
    """
    recs, _, _ = driver.execute_query(check_q, database_="neo4j")
    
    if recs:
        print(f"–ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–µ–π CONTAINS: {recs[0]['count']}")
        for r in recs:
            print(f"  {r['parent_type']} -[:CONTAINS]-> {r['child_type']}: {r['count']}")
    else:
        print("‚úÖ –°–≤—è–∑–µ–π CONTAINS –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return
    
    # Migration
    migrate_q = """
    MATCH (parent)-[old:CONTAINS]->(child)
    MERGE (parent)-[:DECOMPOSES]->(child)
    DELETE old
    RETURN count(*) as migrated
    """
    
    print("\n‚öôÔ∏è –í—ã–ø–æ–ª–Ω—è—é –º–∏–≥—Ä–∞—Ü–∏—é...")
    result, _, _ = driver.execute_query(migrate_q, database_="neo4j")
    print(f"‚úÖ –ú–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ: {result[0]['migrated']} —Å–≤—è–∑–µ–π CONTAINS -> DECOMPOSES")

def remove_noncanonical_relationships():
    """–£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∫–∞–Ω–æ–Ω–∏—á–Ω—ã—Ö —Å–≤—è–∑–µ–π"""
    print("\n" + "=" * 60)
    print("–ó–ê–î–ê–ß–ê 2: –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∫–∞–Ω–æ–Ω–∏—á–Ω—ã—Ö —Å–≤—è–∑–µ–π")
    print("=" * 60)
    
    driver = get_driver()
    
    # Check for non-canonical relationships
    for rel_type in ['ALLOWS_CONNECTION', 'CAN_PERFORM']:
        check_q = f"""
        MATCH ()-[r:{rel_type}]->()
        RETURN count(r) as count
        """
        recs, _, _ = driver.execute_query(check_q, database_="neo4j")
        count = recs[0]['count']
        
        if count > 0:
            print(f"\n‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ —Å–≤—è–∑–µ–π {rel_type}: {count}")
            
            # Show examples
            example_q = f"""
            MATCH (s)-[r:{rel_type}]->(t)
            RETURN s.uid as source, t.uid as target, labels(s)[0] as s_type, labels(t)[0] as t_type
            LIMIT 5
            """
            examples, _, _ = driver.execute_query(example_q, database_="neo4j")
            print(f"  –ü—Ä–∏–º–µ—Ä—ã:")
            for ex in examples:
                print(f"    {ex['s_type']}:{ex['source']} -> {ex['t_type']}:{ex['target']}")
            
            # Delete
            delete_q = f"""
            MATCH ()-[r:{rel_type}]->()
            DELETE r
            RETURN count(*) as deleted
            """
            result, _, _ = driver.execute_query(delete_q, database_="neo4j")
            print(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ: {result[0]['deleted']} —Å–≤—è–∑–µ–π {rel_type}")
        else:
            print(f"‚úÖ –°–≤—è–∑–µ–π {rel_type} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

def find_duplicate_functions():
    """–ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ Functions"""
    print("\n" + "=" * 60)
    print("–ó–ê–î–ê–ß–ê 3: –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ Functions")
    print("=" * 60)
    
    driver = get_driver()
    
    # Find functions with similar names (different underscore patterns)
    q = """
    MATCH (f:Function)
    WHERE f.uid CONTAINS 'graph_sync_py'
    RETURN f.uid as uid, coalesce(f.name, f.uid) as name
    ORDER BY f.uid
    """
    recs, _, _ = driver.execute_query(q, database_="neo4j")
    
    print(f"–ù–∞–π–¥–µ–Ω–æ Functions —Å 'graph_sync_py': {len(recs)}")
    
    # Group by normalized name (replace __ with _)
    groups = {}
    for r in recs:
        uid = r['uid']
        
        # Normalize: replace __ClassName__ with _ClassName_
        normalized = uid.replace('__GraphSync__', '_GraphSync_')
        
        if normalized not in groups:
            groups[normalized] = []
        groups[normalized].append(uid)
    
    duplicates_found = False
    for norm, uids in groups.items():
        if len(uids) > 1:
            duplicates_found = True
            print(f"\n‚ö†Ô∏è –î—É–±–ª–∏–∫–∞—Ç—ã –¥–ª—è {norm}:")
            for uid in uids:
                # Check relationships
                rel_q = """
                MATCH (f {uid: $uid})-[r]-()
                RETURN count(r) as rel_count
                """
                rel_recs, _, _ = driver.execute_query(rel_q, {'uid': uid}, database_="neo4j")
                rel_count = rel_recs[0]['rel_count']
                print(f"    {uid} (—Å–≤—è–∑–µ–π: {rel_count})")
    
    if not duplicates_found:
        print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    return groups

def clean_depends_on_property():
    """–û—á–∏—Å—Ç–∫–∞ —Å–≤–æ–π—Å—Ç–≤–∞ depends_on –∏–∑ File —É–∑–ª–æ–≤"""
    print("\n" + "=" * 60)
    print("–ó–ê–î–ê–ß–ê 4: –û—á–∏—Å—Ç–∫–∞ —Å–≤–æ–π—Å—Ç–≤–∞ depends_on")
    print("=" * 60)
    
    driver = get_driver()
    
    # Check for nodes with depends_on property
    check_q = """
    MATCH (n:File)
    WHERE n.depends_on IS NOT NULL
    RETURN count(n) as count
    """
    recs, _, _ = driver.execute_query(check_q, database_="neo4j")
    count = recs[0]['count']
    
    if count > 0:
        print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ File —É–∑–ª–æ–≤ —Å —Å–≤–æ–π—Å—Ç–≤–æ–º depends_on: {count}")
        
        # Remove property
        remove_q = """
        MATCH (n:File)
        WHERE n.depends_on IS NOT NULL
        REMOVE n.depends_on
        RETURN count(n) as cleaned
        """
        result, _, _ = driver.execute_query(remove_q, database_="neo4j")
        print(f"‚úÖ –û—á–∏—â–µ–Ω–æ —É–∑–ª–æ–≤: {result[0]['cleaned']}")
    else:
        print("‚úÖ –°–≤–æ–π—Å—Ç–≤–∞ depends_on –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

def main():
    print("üîß –ú–ê–°–°–û–í–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ì–†–ê–§–ê")
    print("=" * 60)
    
    try:
        # 1. Migrate CONTAINS
        migrate_contains_to_decomposes()
        
        # 2. Remove non-canonical rels
        remove_noncanonical_relationships()
        
        # 3. Find duplicates (reporting only)
        duplicate_groups = find_duplicate_functions()
        
        # 4. Clean depends_on property
        clean_depends_on_property()
        
        print("\n" + "=" * 60)
        print("‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –ó–ê–í–ï–†–®–ï–ù–´")
        print("=" * 60)
        print("\nüí° –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
        print("1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é: sync_all()")
        print("2. –£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã Functions –≤—Ä—É—á–Ω—É—é (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã)")
        print("3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å find_orphans —Å–Ω–æ–≤–∞")
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
    finally:
        close_driver()

if __name__ == "__main__":
    main()
